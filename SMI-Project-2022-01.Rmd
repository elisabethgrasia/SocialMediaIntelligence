---
title: "Social Media Intelligence Project"
author: "Elisabeth Putri - 20306250"
date: "27/05/2022"
output:
  word_document: default
  word: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

By including this statement, we the authors of this work, verify that:
  • I hold a copy of this assignment that we can produce if the original is     lost or damaged.
  • I hereby certify that no part of this assignment/product has been copied     from any other student’s work or from any other source except where due     acknowledgement is made in the assignment.
  • No part of this assignment/product has been written/produced for us by      another person except where such collaboration has been authorised by       the subject lecturer/tutor concerned.
  • I am aware that this work may be reproduced and submitted to plagiarism     detection software programs for the purpose of detecting possible           plagiarism (which may retain a copy on its database for future              plagiarism checking).
  • I hereby certify that we have read and understand what the School of        Computing and Mathematics defines as minor and substantial breaches of      misconduct as outlined in the learning guide for this unit.


Before we start the coding, importing all the library.
```{r}
library('igraph')
library('rtweet')
library('tm')
library('dplyr')
```



1. Gathering the Network

```{r}
em <- search_tweets(
  "#elonmusktwitter", n=25000, include_rts = FALSE, retryonratelimit = TRUE)

names(em)
tweettext = as.data.frame(em$text, em$screen_name)
print(head(tweettext))
```

2. Mention Graph
```{r}
# Create graph on the mentions in each tweet
datatw = network_data(em, "mention")

gnet <- graph_from_data_frame(datatw, directed = TRUE)

par(mar = c(0, 0, 0, 0))
V(gnet)$label.cex=0.2
plot(gnet, layout = layout.fruchterman.reingold, vertex.size = 30)

# Convert the directed graph into undirected graph
convertem <- graph_from_data_frame(datatw, directed = FALSE)

par(mar = c(0, 0, 0, 0))
V(convertem)$label.cex=0.1
plot(convertem, layout = layout.fruchterman.reingold, vertex.size = 30)

# Compute the number of components and size of each components
# number of components
count_components(convertem)
# size of each components
aa = components(convertem)
aa$csize

# Plot the largest component of the graph
## First split the components of the graph
deco = decompose(convertem)

## nodes number in each component
nc = sapply(deco, function(x) {length(V(x))})

## index of largest component
lc = which(nc == max(nc))

## largest component's edges
lce = deco[[lc]]

## largest component graph
lcgraph = cluster_edge_betweenness(lce, directed = FALSE)

# check all partition
print(lcgraph$membership)

# check all the edges
table(lcgraph$membership) 

## By checking all the edges, the highest number is 1, so we use 1 as the largest component
lcno = 1
indexlc = which(lcgraph$membership == lcno)

## Taking the nodes from largest component to be plotted
lcgraphed = subgraph(deco[[lc]], indexlc)
plot(lcgraphed, vertex.size=5)

## Graph partition by hierarchical relationship
plot(as.dendrogram(lcgraph)) 

```

3. Graph Statistics

```{r}
# graph diameter
diameter(lcgraphed)

# graph density
graph.density(lcgraphed)

# plotting the degree distribution of the graph
degree(lcgraphed)
max(degree(lcgraphed))
dd = degree.distribution(lcgraphed)
hist(dd)

# estimating the Power Law coefficient(c) from the degree distribution
pl = fit_power_law(dd, xmin = 0.000000000000000001)
print(pl)
print(pl)$alpha
```
```
4. Information Flow

```{r}
# neighourhood overlap between each pair of connected nodes in the twitter graph 
# changing the name of the vertex to easier analysis process
bb = set.vertex.attribute(lcgraphed, "name", value = paste("A",1:146, sep = ""))

en = ends(bb, E(bb), names = FALSE)

ne.over = function(no1, no2, graphed) {
  i = intersection(neighbors(graphed, no1), neighbors(graphed, no2))
  u = union(neighbors(graphed, no1), neighbors(graphed, no2))
  a = length(i)/ (length(u)) 
  return(a)
}

nodes = list()

for (i in seq(nrow(en))){
  node1 = en[i, 1]
  node2 = en[i, 2]
  nover = ne.over(no1 = node1, no2 = node2, graphed = bb)
  nodes[i] = nover
}


# identify the pair with the greatest and least neighborhood overlap
d = c()

for (i in 1:length(nodes)){
  d[i] = nodes[[i]][1]
}

l = d[order(d,decreasing=TRUE)]
#l

# greatest and least neighborhood overlap
V(lcgraphed)[76, 117]
print(head(E(lcgraphed))) 

#em %>% filter_at(vars(user_id, reply_to_user_id), any_vars(. %in% c("44196397")))

#em %>% filter_at(vars(user_id, reply_to_user_id), any_vars(. %in% c("1449308487238963204")))

# "44196397" is id for Elon musk's twitter id, which is mentioned by 73 tweets in this dataset
```




5. Account Popularity
```{r}
# Measuring popularity of each account by Scaled PageRank

hu = rep(1, length(names(V(bb))))
names(hu) = names(V(bb))
au = hu

M = as_adjacency_matrix(bb)
M = as.matrix(M)

## iterate K times
ik = 100
for (i in 1:ik) {
  au = t(M) %*% hu
  hu = M %*% au
}

au = au/sum(au)
hu = hu/sum(hu)

# eigenvalue solution
ed1 = eigen(M %*% t(M))
hub.ed = ed1$vectors[,1]

ed2 = eigen(t(M) %*% M)
au.ed = ed2$vectors[,1]

hub.ed = hub.ed/sum(hub.ed)
au.ed = au.ed/sum(au.ed)

# Result checking
au - au.ed
hu - hub.ed

## PageRank

P = M %*% diag(1/colSums(M))
nonodes = nrow(P)
R = matrix(1/nonodes, nonodes, nonodes) 

ld = 0.8
S = ld*P + (1-ld)*R
colSums(S)

iter = rep(1/nonodes, nonodes)
for (k in 1:ik) {
  iter = S %*% iter
}

e.val = eigen(S)

pr = e.val$vector[,1]/sum(e.val$vector[,1])
pr = Re(pr)

#checking method
iter - pr

# Ten highest page rank
pro = sort(pr, index.return=TRUE)
pro$ix[1:10]

prorder = pr[order(pr,decreasing=TRUE)]
prorder[1:10]

V(lcgraphed)[141, 142, 143, 1, 8, 9, 10, 11, 13, 16]
em %>% filter_at(vars(user_id, reply_to_user_id), any_vars(. %in% c("6182852", "128372940", "51827346", "1513921541918138372", "1316181534", "1021241294", "1450520650335072262", "1452304054206488576", "1510000127745970186", "1423355927302975489")))
```

6. Account Selection
explained manually in the report